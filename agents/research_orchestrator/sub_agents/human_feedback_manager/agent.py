from strands import Agent, tool
from strands_tools import handoff_to_user
from jinja2 import Environment
from typing import Optional
from domain import HumanFeedbackDecision, ResearchPlan, QueryAnalysis

human_feedback_manager_prompt = """
You are a human feedback manager. You are responsible for presenting a complex research plan to the user, and analyzing the user feedback to decide how to proceed further in the research.
Your expertise is in parsing complex json structures of a research plan which could be of following types:
- StraightforwardResearchPlan
- DepthFirstResearchPlan
- BreadthFirstResearchPlan
This plan was generated by several agents by determining the user query type, and decomposing the user query into individual components.

You are given this information for 2 purposes:
1. To present the generated plan to the user in a way that is easy to understand and follow and yet concise.
2. To analyze the user feedback and decide whether to modify the existing research plan or develop a new one.

<guidelines_for_presenting_the_plan>
The presented plan must:
- Not include any extra information that is not part of the research plan, user query, or the query analysis.
- Must not contain or reproduce any complex json structures from the structured research plan provided.
- Only include the relevant high level information that a human would follow to understand how the research objective is structured.
</guidelines_for_presenting_the_plan>

<guidelines_for_analyzing_the_feedback>
You have to make one of the following decisions based on the user feedback, the plan that was presented, and details from the previous query analysis:
- Do nothing and continue with the existing plan. This is the default option and should be considered when the user feedback is not significant or does not deviate significantly from the existing plan, or if the user approves the existing plan.
- Use most of the existing plan as it is and only add or change a few aspects of it to accomodate the users feedback.
- Reuse existing steps/aspects of the existing plan but redevelop a new plan with same or different approach to accomodate the users feedback.
- Develop a new research plan from scratch ONLY because the user feedback deviates significantly the existing plan and the query components analyzed previously. This is a costly operation and therefore should be considered when the user feedback absolutely necessitates it. Choosing this option will rerun the query analysis workflow again.
- The key to this decision is to compare the feedback with juxtaposed to the previously analyzed query components to deem if they deviate significantly.
- In addition you must provide feedback on how to modify the existing plan
</guidelines_for_analyzing_the_feedback>

The response should con
"""

human_feedback_manager = Agent(
    name="human_feedback_manager",
    description="""This agent is responsible for analyzing human feedback and deciding whether to modify the existing research plan or develop a new one""",
    system_prompt=human_feedback_manager_prompt,
    model="gemini-2.5-flash",
    # tools=[ This will not work well. We need to setup the ui for this.
    #     handoff_to_user
    # ]
)



async def manage_human_feedback(
        user_feedback: Optional[str]=None, 
        research_plan: Optional[ResearchPlan]=None, 
        query_analysis: Optional[QueryAnalysis]=None
    ) -> str:
        prompt = """
        {% if user_feedback %}
            Here is the user feedback on the research plan:
            
            {user_feedback}
            
            The user feedback was for the following plan:

            {research_plan}

            Here is the query analysis based on which the plan was generated:
            
            Query Type: {query_type}
            Reasoning for the query type: {query_type_reasoning}
            
            Query Components:
            {query_components}
            
        {% else %}
            Here is the research plan that you must present to the user:

                {research_plan}
        
            Here is the query analysis results:
        
            Query Type: {query_type}
            Reasoning for the query type: {query_type_reasoning}

            Query Components:
            {query_components}
        {% endif %}"""
    
        prompt = Environment() \
        .from_string(prompt) \
        .render(
            user_feedback=user_feedback,
            research_plan=research_plan,
            query_type=query_analysis.query_type,
            query_type_reasoning=query_analysis.query_type_reasoning,
            query_components=query_analysis.query_components,
        )

        return await human_feedback_manager.structured_output_async(HumanFeedbackDecision,prompt)

